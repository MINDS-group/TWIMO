{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sHIof7Hx1jOF"},"outputs":[],"source":["import pandas as pd\n","import math\n","import glob\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","#from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","#from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import median_absolute_error\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.layers import LSTM\n"]},{"cell_type":"code","source":["path = r'/content/drive/MyDrive/AVL-RDE'\n","all_csv_files = glob.glob(path + \"/*.csv\")\n","print(len(all_csv_files))\n","#Read each CSV file into DataFrame\n","#This creates a list of dataframes\n","df_lists = (pd.read_csv(file) for file in all_csv_files)\n","#concatenate all DataFrames\n","big_df   = pd.concat(df_lists, ignore_index=True)\n","sc_bg = StandardScaler()\n","big_scaled_dataset = sc_bg.fit_transform(big_df)\n","\n","pca_test = PCA(n_components=9, svd_solver='auto')\n","pca_test.fit(big_scaled_dataset)\n","sns.set(style='whitegrid')\n","plt.plot(np.cumsum(pca_test.explained_variance_ratio_))\n","plt.xlabel('number of components')\n","plt.ylabel('cumulative explained variance')\n","plt.axvline(linewidth=4, color='r', linestyle = '--', x=10, ymin=0, ymax=1)\n","display(plt.show())\n","evr = pca_test.explained_variance_ratio_\n","cvr = np.cumsum(pca_test.explained_variance_ratio_)\n","pca_df = pd.DataFrame()\n","pca_df['Cumulative Variance Ratio'] = cvr\n","pca_df['Explained Variance Ratio'] = evr\n","display(pca_df.head(10))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"lUWCPZ6XIW-9","executionInfo":{"status":"error","timestamp":1658326234001,"user_tz":-120,"elapsed":938,"user":{"displayName":"Matteo Spezialetti","userId":"00791735402973887227"}},"outputId":"e7342f99-75b6-4bac-a4ab-1bda204e569f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-66d59cea8397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_csv_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#concatenate all DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbig_df\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_lists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0msc_bg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbig_scaled_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc_bg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: No objects to concatenate"]}]},{"cell_type":"code","source":["from pandas.core.common import standardize_mapping\n","path = r'/content/drive/MyDrive/AVL-RDE'\n","csv_files = glob.glob(path + \"/*.csv\")\n","Accumulated=[]\n","for i in range (len(csv_files)):\n"," temp_csv_files=csv_files.copy()\n"," csv_test = temp_csv_files.pop(i)\n"," print(csv_test)\n"," test = pd.read_csv(csv_test)\n"," train = pd.concat([pd.read_csv(f) for f in temp_csv_files])\n"," colsTrain = list(train)[1:10]\n"," colsTest  = list(test)[1:10]\n"," print(colsTrain)\n"," print(colsTest)\n"," df_for_training = train[colsTrain].astype(float)\n"," df_for_testing  =  test[colsTest].astype(float)\n"," print(df_for_training.info())\n"," print(df_for_testing.info())\n"," print(df_for_testing.head())\n"," scalar = StandardScaler()\n"," df_for_training_scaled = scalar.fit_transform(df_for_training)\n"," df_for_testing_scaled =  scalar.transform(df_for_testing)\n"," print('df_for_training_scaled.shape', df_for_training_scaled.shape)\n"," print('df_for_testing_scaled.shape', df_for_testing_scaled.shape)\n","\n"," trainX=[]\n"," trainY=[]\n"," testX=[]\n"," testY=[]\n","\n"," n_future=1\n"," n_past=20\n","\n"," for i in range(n_past, len(df_for_training_scaled) - n_future +1):\n","    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n","    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 8])\n","\n"," trainX, trainY = np.array(trainX), np.array(trainY)\n"," print('trainX shape == {}.'.format(trainX.shape))\n"," print('trainY shape == {}.'.format(trainY.shape))\n","\n","\n"," for i in range(n_past, len(df_for_testing_scaled) - n_future +1):\n","    testX.append(df_for_testing_scaled[i - n_past:i, 0:df_for_testing.shape[1]])\n","    testY.append(df_for_testing_scaled[i + n_future - 1:i + n_future, 8])\n","\n"," testX, testY = np.array(testX), np.array(testY)\n"," print('testX shape == {}.'.format(testX.shape))\n"," print('testY shape == {}.'.format(testY.shape))\n","\n","\n","\n","# define the Autoencoder model\n","#======================\n"," model = Sequential()\n"," model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n"," model.add(LSTM(32, activation='relu', return_sequences=False))\n"," model.add(Dropout(0.2))\n"," model.add(Dense(trainY.shape[1]))\n","\n"," model.compile(optimizer='adam', loss='mse', metrics='mse')\n"," model.summary()\n","#=========================\n","# fit the model\n"," #history = \n"," model.fit(trainX, trainY, epochs=1, batch_size=16, validation_split=0.1, verbose=1)\n"," #plt.plot(history.history['loss'], label='Training loss')\n"," #plt.plot(history.history['val_loss'], label='Validation loss')\n"," #plt.legend()\n","\n"," y_prediction=model.predict(testX, verbose=0)\n"," y_prediction_copies = np.repeat(y_prediction, df_for_testing_scaled.shape[1], axis=-1)\n"," print(y_prediction_copies)\n"," y_prediction_inverse = scalar.inverse_transform(y_prediction_copies)[:,0]\n"," print(y_prediction_inverse.shape)\n"," print(y_prediction_inverse)\n","\n","\n"," y_testing_copies = np.repeat(testY, df_for_testing_scaled.shape[1], axis=-1)\n"," print('y_testing_copies: ', y_testing_copies)\n"," y_testing_inverse = scalar.inverse_transform(y_testing_copies)[:,0]\n"," print(y_testing_inverse.shape)\n"," print(y_testing_inverse)\n"," Accumulated.append(mean_absolute_error(y_testing_inverse, y_prediction_inverse))\n"," print(Accumulated)\n"," print('==================================================================')\n","print('Average MSE for All Runs is: ',np.mean(Accumulated))\n","\n","\n","\n","\n"," \n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"FId4zlKRLqpl","outputId":"e4c582c5-4abd-4048-cf58-3722bfeada25","executionInfo":{"status":"error","timestamp":1658324752513,"user_tz":-180,"elapsed":1755909,"user":{"displayName":"Hamzeh Eyal Salman","userId":"13186293692592161293"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AVL-RDE/19_Highway_DGPS_dyn_22082017_city_part.csv\n","['d', 'spd_lim', 'tfc_flw', 'traf_lig', 'tfc_sgn', 'toll_booth', 'curvature', 'slope', 'velocity_kmh_raw']\n","['d', 'spd_lim', 'tfc_flw', 'traf_lig', 'tfc_sgn', 'toll_booth', 'curvature', 'slope', 'velocity_kmh_raw']\n","<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 467999 entries, 0 to 62153\n","Data columns (total 9 columns):\n"," #   Column            Non-Null Count   Dtype  \n","---  ------            --------------   -----  \n"," 0   d                 467999 non-null  float64\n"," 1   spd_lim           467999 non-null  float64\n"," 2   tfc_flw           467999 non-null  float64\n"," 3   traf_lig          467999 non-null  float64\n"," 4   tfc_sgn           467999 non-null  float64\n"," 5   toll_booth        467999 non-null  float64\n"," 6   curvature         467999 non-null  float64\n"," 7   slope             467999 non-null  float64\n"," 8   velocity_kmh_raw  467999 non-null  float64\n","dtypes: float64(9)\n","memory usage: 35.7 MB\n","None\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 830 entries, 0 to 829\n","Data columns (total 9 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   d                 830 non-null    float64\n"," 1   spd_lim           830 non-null    float64\n"," 2   tfc_flw           830 non-null    float64\n"," 3   traf_lig          830 non-null    float64\n"," 4   tfc_sgn           830 non-null    float64\n"," 5   toll_booth        830 non-null    float64\n"," 6   curvature         830 non-null    float64\n"," 7   slope             830 non-null    float64\n"," 8   velocity_kmh_raw  830 non-null    float64\n","dtypes: float64(9)\n","memory usage: 58.5 KB\n","None\n","            d  spd_lim  tfc_flw  traf_lig  tfc_sgn  toll_booth  curvature  \\\n","0   79.976352     50.0     40.0       0.0      0.0         0.0   0.000033   \n","1   86.376645     50.0     40.0       0.0      0.0         0.0   0.000039   \n","2   92.904255     50.0     40.0       0.0      0.0         0.0   0.000048   \n","3   99.362592     50.0     40.0       0.0      0.0         0.0   0.000046   \n","4  105.751485     50.0     40.0       0.0      0.0         0.0   0.000018   \n","\n","      slope  velocity_kmh_raw  \n","0 -0.560175         45.166627  \n","1 -0.568272         46.997593  \n","2 -0.575747         47.000000  \n","3 -0.582367         46.000053  \n","4 -0.588226         46.000000  \n","df_for_training_scaled.shape (467999, 9)\n","df_for_testing_scaled.shape (830, 9)\n","trainX shape == (467979, 20, 9).\n","trainY shape == (467979, 1).\n","testX shape == (810, 20, 9).\n","testY shape == (810, 1).\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 20, 64)            18944     \n","                                                                 \n"," lstm_1 (LSTM)               (None, 32)                12416     \n","                                                                 \n"," dropout (Dropout)           (None, 32)                0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 31,393\n","Trainable params: 31,393\n","Non-trainable params: 0\n","_________________________________________________________________\n","26324/26324 [==============================] - 535s 20ms/step - loss: 4.9683 - accuracy: 0.0000e+00 - val_loss: 0.0332 - val_accuracy: 0.0000e+00\n","[[0.10539368 0.10539368 0.10539368 ... 0.10539368 0.10539368 0.10539368]\n"," [0.09881413 0.09881413 0.09881413 ... 0.09881413 0.09881413 0.09881413]\n"," [0.09056949 0.09056949 0.09056949 ... 0.09056949 0.09056949 0.09056949]\n"," ...\n"," [1.4730492  1.4730492  1.4730492  ... 1.4730492  1.4730492  1.4730492 ]\n"," [1.457058   1.457058   1.457058   ... 1.457058   1.457058   1.457058  ]\n"," [1.4416723  1.4416723  1.4416723  ... 1.4416723  1.4416723  1.4416723 ]]\n","(810,)\n","[38245.64    38044.69    37792.887   37586.723   37447.668   37131.383\n"," 36842.17    36359.184   35920.363   35352.25    34638.23    34035.223\n"," 33373.664   32655.764   32112.193   31369.068   30696.69    30212.738\n"," 29662.1     29230.135   29248.264   29357.662   29480.465   29583.482\n"," 29904.176   30493.344   31033.727   31669.273   32146.648   32450.396\n"," 32839.56    32924.188   33332.83    33756.773   34324.555   34803.04\n"," 35121.      35066.516   34878.438   34679.438   34328.992   33972.63\n"," 33684.91    33496.555   29623.016   32491.895   32820.734   32964.375\n"," 33335.234   33735.418   33686.086   33380.66    33118.977   32604.95\n"," 32198.795   31930.318   31821.908   31592.283   31648.51    31867.154\n"," 32420.047   32941.414   33377.008   33724.254   33405.31    33437.766\n"," 33668.48    33921.67    34151.055   34287.812   34344.703   34365.2\n"," 34360.72    34574.156   34833.754   35291.39    35959.418   36533.61\n"," 36933.457   37154.812   37257.562   37294.727   37284.375   37268.62\n"," 37262.734   37008.137   36713.695   36731.223   36846.867   36968.01\n"," 37088.86    37167.816   37205.17    36991.39    36732.74    36503.355\n"," 36353.004   36283.137   36244.605   36239.23    36251.71    36253.44\n"," 36259.883   36271.1     36268.547   36254.44    36267.617   32863.594\n"," 35003.258   35166.39    35127.73    35449.133   35917.92    36159.99\n"," 35944.516   36256.227   36651.26    36930.387   37290.84    37861.266\n"," 38340.016   38677.47    39148.19    39565.414   39873.914   40296.54\n"," 40668.87    40652.42    40761.387   40793.12    40794.523   40784.6\n"," 40767.023   40769.7     40992.785   41213.434   41391.613   41510.273\n"," 41572.098   41611.215   41411.305   41197.78    41034.535   40908.36\n"," 40833.58    41017.43    41222.992   41594.68    41926.656   42163.645\n"," 42318.207   42406.867   42449.027   42275.29    40035.637   40372.355\n"," 39922.6     39940.523   40204.65    40466.4     40670.223   40615.34\n"," 40561.312   40497.082   40420.625   40334.992   40255.086   40182.62\n"," 40132.26    40108.094   40105.637   39903.074   39702.566   39576.816\n"," 39059.164   38708.555   38148.76    37422.332   36606.527   35387.227\n"," 34580.24    33727.688   32545.982   31021.17    28918.988   26704.426\n"," 24187.662   21683.951   18892.367   16320.508   13603.076   11151.904\n","  8442.83     5973.3276   3737.437    2098.3452    838.6656   -203.5219\n"," -1663.1312  -2927.2876  -4068.3267  -5678.768   -7018.7095  -7649.3774\n"," -7936.3813  -8092.487   -8232.412   -8407.076   -8598.795   -8758.541\n"," -8849.975   -8873.393   -8860.549   -8845.67    -8843.834   -8855.725\n"," -8874.939   -8890.49    -8899.498   -8898.314   -8891.033   -8887.615\n"," -8887.611   -8883.334   -8349.482   -7034.405   -5346.9204  -2786.4673\n","  -628.5649   1001.71246  2953.4175   4499.64     5756.687    6907.488\n","  8431.346    9793.002   11061.404   12707.902   14220.561   15552.809\n"," 16724.174   17762.629   18378.91    19144.035   20071.598   21063.646\n"," 22034.121   22647.318   23384.664   24259.559   25163.428   25720.307\n"," 26371.693   27153.24    27997.334   28867.748   29508.12    30181.66\n"," 30649.605   30901.324   30981.46    31145.674   31395.764   31616.855\n"," 31733.094   32033.023   32333.322   32531.38    32854.344   33142.45\n"," 33366.016   33492.72    33759.336   34271.45    34733.18    35276.895\n"," 35738.215   36289.957   36714.715   36995.77    37142.945   37352.895\n"," 37602.066   37780.957   37879.246   38070.684   38298.746   38462.152\n"," 38561.63    38392.113   38150.707   37946.01    37831.043   37789.246\n"," 37780.668   37610.234   37443.312   37131.965   36673.36    36273.062\n"," 35789.78    35175.77    16037.303   15920.35    25353.2     31587.033\n"," 35375.66    36640.145   36505.73    34802.832   33038.52    31189.465\n"," 29266.76    27648.418   26604.135   26137.469   26114.17    26439.953\n"," 26962.773   27464.252   27839.578   28320.568   28351.938   28317.97\n"," 28220.387   28002.23    27525.543   26865.75    25871.252   24521.709\n"," 22477.977   19851.943   16513.875   12567.486    8032.734    2858.8843\n"," -1455.2875  -4613.346   -6503.643   -7542.5806  -8065.7446  -8375.256\n"," -8591.154   -8738.963   -8828.932   -8857.061   -8841.486   -8805.236\n"," -8775.92    -8773.111   -8781.33    -8799.928   -8818.439   -8833.033\n"," -8838.166   -8839.982   -8839.541   -8839.271   -8839.014   -8839.014\n"," -8839.014   -8839.014   -8839.014   -7835.9946  -5816.772   -3330.268\n"," -1132.9203    872.607    2798.519    4274.4644   5467.222    6576.437\n","  7712.9175   9571.115   10980.674   12216.672   13217.184   13909.908\n"," 14246.193   14376.941   14705.447   15457.025   16477.139    8042.818\n","  8623.334   17642.545   25198.277   28559.752   28491.494   26511.604\n"," 24255.527   22574.303   21182.523   19855.586   18596.877   17388.947\n"," 16481.375   16945.795   17745.79    18706.805   19735.457   20725.879\n"," 21415.29    21321.525   21880.05    22984.713   24340.885   25717.176\n"," 26975.523   27808.768   28275.248   28496.365   28553.162   28210.756\n"," 27906.293   27397.602   26626.564   26009.836   25301.97    24799.082\n"," 24428.186   23798.29    11540.244   12842.514   19710.367   25424.225\n"," 27711.582   26898.35    25262.295   23390.783   21579.707   20417.291\n"," 19156.969   17859.195   17104.336   16556.354   16520.143   16431.299\n"," 16487.014   15866.982   14316.139   12597.34    10309.783    7553.1616\n","  4519.228    1426.4352  -1628.6898  -4161.932   -5815.319   -6965.8657\n"," -7420.108   -7624.0923  -7803.979   -8010.2603  -8227.568   -8413.744\n"," -8542.553   -8612.482   -8648.158   -8675.311   -8707.971   -8747.545\n"," -8786.127   -8813.83    -8828.291   -8833.463   -8832.717   -8831.041\n"," -8828.83    -8828.83    -8828.83    -8828.83    -8828.83    -8828.83\n"," -8828.83    -8828.83    -8828.83    -8828.83    -8828.838   -8828.838\n"," -8828.83    -8828.83    -8828.83    -8828.83    -8828.83    -8828.83\n"," -8828.83    -8828.83    -8828.83    -8828.83    -8828.83    -8828.83\n"," -8828.83    -8828.83    -8828.83    -8828.83    -8828.83    -8828.83\n"," -8828.83    -8828.83    -8828.83    -8828.83    -8828.83    -8828.83\n"," -8828.83    -8828.83    -8828.83    -8828.83    -8828.83    -8828.83\n"," -8828.838   -8828.838   -8828.83    -8828.83    -8828.83    -8828.83\n"," -8828.83    -8306.064   -8035.85    -7930.4243  -7377.3735  -7105.983\n"," -6485.8696  -5651.655   -4729.5103  -3274.4556  -2043.4359   -483.55707\n","  1283.2555   2206.7202   3156.9546   4171.738    4763.2144   5077.2456\n","  5175.8315   5192.1343   5236.101    5304.1265   4958.4917   5486.431\n","  6650.013    8129.9956   9663.105   11073.814   11808.283   12444.293\n"," 13120.369   13895.064   14368.102   14626.684   15605.836   16331.461\n"," 17575.129   19228.994   20717.24    22012.52    23156.19    24664.285\n"," 26529.71    28159.158   29425.725   30485.523   31278.328   31635.53\n"," 31959.607   32119.527   32150.082   32444.127   32738.34    33160.668\n"," 33534.44    33984.152   34370.266   34836.19    35378.19    36247.76\n"," 37313.33    38409.348   39455.98    40238.227   40745.348   41061.81\n"," 41239.48    41330.598   41371.316   41192.336   40988.254   40830.55\n"," 40738.47    40284.637   40044.84    39727.336   39680.082   39715.1\n"," 39788.324   40065.71    40559.836   41238.83    42256.953   43388.117\n"," 44668.09    45853.094   47138.207   48671.785   50349.707   52044.21\n"," 53725.586   55473.25    57212.855   58637.684   60450.125   62458.848\n"," 64585.902   66589.73    68171.11    69275.14    69748.336   69878.44\n"," 69612.05    69034.18    68356.164   67587.375   66875.22    66089.48\n"," 65456.895   65009.223   64733.277   64555.562   64488.95    64736.902\n"," 65287.008   65852.1     66554.57    67410.28    68391.55    69422.92\n"," 70483.87    71345.92    71969.125   72146.26    72337.82    72455.89\n"," 72507.05    72335.914   72064.13    71563.56    71106.21    70751.15\n"," 70507.85    70379.84    70544.77    70785.92    71239.67    71895.14\n"," 72968.17    74198.8     74995.7     76160.766   77104.65    77769.38\n"," 78164.46    78527.766   79103.61    80046.8     81099.04    82391.695\n"," 83894.88    85324.97    86612.92    87559.07    87944.03    88091.8\n"," 88142.78    87937.77    87578.016   87222.89    86836.94    86484.54\n"," 86258.625   86377.41    86801.92    87212.375   87758.195   88417.45\n"," 89168.77    89966.81    90781.445   91370.234   91733.38    91930.13\n"," 91085.65    90936.195   90017.47    89939.63    90047.71    90236.79\n"," 90403.69    90690.69    90065.02    90529.445   91135.2     91680.664\n"," 92040.086   92247.03    92347.92    92228.02    92004.03    91805.586\n"," 91512.84    91201.01    90830.43    90462.695   90229.73    90077.91\n"," 90001.4     90141.27    90518.81    91080.42    91877.625   92650.12\n"," 93264.68    93659.07    93873.164   93972.28    94009.51    94025.51\n"," 94036.03    94048.53    94308.9     94564.234   94770.984   94910.56\n"," 95000.875   95061.73    95106.664   95140.18    95165.945   95185.7\n"," 95197.5     95205.4     95212.875   94979.07    94759.25    94596.54\n"," 94502.74    94456.836   94439.32    94436.266   94431.79    94428.45\n"," 94424.15    94418.195   94160.82    93195.46    93061.695   93115.51\n"," 93009.164   92893.11    92547.47    92250.695   91792.59    91436.164\n"," 90950.01    90394.78    89913.21    89335.95    88894.68    88356.92\n"," 87947.75    87424.07    87012.73    85774.17    85390.51    85034.08\n"," 84797.51    84623.91    84279.71    83968.24    83496.88    82750.01\n"," 82233.38    81871.7     81647.69    81280.4     80966.47    80735.11\n"," 80568.805   80457.85    80368.22    80302.52    80241.62    80208.59\n"," 80157.47    80112.9     80067.66    79787.83    79512.555   79279.27\n"," 79094.84    78633.875   78745.26    78940.89    79339.87    79681.1\n"," 80136.21    80484.97    80325.47    80015.984   79527.586   79057.69   ]\n","y_testing_copies:  [[0.06682573 0.06682573 0.06682573 ... 0.06682573 0.06682573 0.06682573]\n"," [0.06142825 0.06142825 0.06142825 ... 0.06142825 0.06142825 0.06142825]\n"," [0.06142825 0.06142825 0.06142825 ... 0.06142825 0.06142825 0.06142825]\n"," ...\n"," [1.4022746  1.4022746  1.4022746  ... 1.4022746  1.4022746  1.4022746 ]\n"," [1.4022746  1.4022746  1.4022746  ... 1.4022746  1.4022746  1.4022746 ]\n"," [1.36957103 1.36957103 1.36957103 ... 1.36957103 1.36957103 1.36957103]]\n","(810,)\n","[ 3.70677139e+04  3.69028666e+04  3.69028666e+04  3.69028666e+04\n","  3.59056864e+04  3.59040483e+04  3.49052301e+04  3.49052301e+04\n","  3.39064118e+04  3.29075935e+04  3.29075935e+04  3.19002499e+04\n","  3.09099570e+04  3.09099570e+04  2.91619549e+04  2.89123205e+04\n","  2.89123205e+04  2.79135611e+04  2.79135022e+04  2.89123205e+04\n","  2.89123205e+04  2.89123205e+04  2.89123205e+04  2.99111387e+04\n","  3.09099570e+04  3.09099570e+04  3.19087753e+04  3.19087753e+04\n","  3.19087753e+04  3.29075935e+04  3.19087753e+04  3.39064118e+04\n","  3.39064118e+04  3.49052301e+04  3.49052301e+04  3.49052301e+04\n","  3.39064118e+04  3.39064118e+04  3.39064118e+04  3.31241222e+04\n","  3.29075935e+04  3.29075935e+04  3.29075935e+04  3.29075935e+04\n","  3.29075935e+04  3.29075935e+04  3.29075935e+04  3.39063608e+04\n","  3.39064118e+04  3.29075935e+04  3.29075935e+04  3.29075935e+04\n","  3.19087753e+04  3.19087753e+04  3.19087753e+04  3.19087753e+04\n","  3.09099570e+04  3.19087753e+04  3.19173090e+04  3.29075935e+04\n","  3.29075935e+04  3.29075935e+04  3.29075935e+04  3.29075935e+04\n","  3.29075935e+04  3.39063493e+04  3.39064118e+04  3.39064118e+04\n","  3.39064118e+04  3.39064118e+04  3.39064118e+04  3.39064118e+04\n","  3.49052301e+04  3.49052301e+04  3.59124202e+04  3.69028666e+04\n","  3.69028666e+04  3.69028666e+04  3.69028666e+04  3.69028666e+04\n","  3.69028666e+04  3.69028666e+04  3.69028666e+04  3.69028666e+04\n","  3.59040883e+04  3.59040483e+04  3.69028666e+04  3.69028666e+04\n","  3.69028666e+04  3.69028666e+04  3.69028666e+04  3.69028666e+04\n","  3.59040483e+04  3.59040483e+04  3.59040483e+04  3.59040483e+04\n","  3.59040483e+04  3.59040483e+04  3.59040483e+04  3.59040483e+04\n","  3.59040483e+04  3.59040483e+04  3.59040483e+04  3.59040483e+04\n","  3.59040483e+04  3.59040483e+04  3.59040483e+04  3.59040483e+04\n","  3.59040483e+04  3.59040483e+04  3.59040483e+04  3.59040483e+04\n","  3.59040483e+04  3.49052301e+04  3.69028666e+04  3.69028666e+04\n","  3.69028666e+04  3.77768624e+04  3.88958328e+04  3.89005031e+04\n","  3.89005031e+04  3.98993214e+04  3.98993214e+04  3.98993214e+04\n","  4.08981396e+04  4.08981396e+04  4.08981396e+04  4.08981396e+04\n","  4.08981396e+04  4.08981396e+04  4.08981396e+04  4.08981396e+04\n","  4.08981396e+04  4.18969280e+04  4.18969579e+04  4.18969579e+04\n","  4.18969579e+04  4.18969579e+04  4.18969579e+04  4.08981396e+04\n","  4.08981396e+04  4.08981396e+04  4.08981396e+04  4.08981396e+04\n","  4.18969579e+04  4.18969579e+04  4.28957762e+04  4.28957762e+04\n","  4.28957762e+04  4.28957762e+04  4.28957762e+04  4.28957762e+04\n","  4.18969579e+04  4.18969579e+04  4.18969579e+04  4.18969579e+04\n","  4.18969579e+04  4.08981396e+04  4.08981396e+04  4.08981396e+04\n","  3.98993617e+04  3.98993214e+04  3.98993214e+04  3.98993214e+04\n","  3.98993214e+04  3.98993214e+04  3.98993214e+04  3.98993214e+04\n","  3.98993214e+04  3.98993214e+04  3.89005031e+04  3.89005031e+04\n","  3.89005031e+04  3.79016848e+04  3.79016848e+04  3.69028666e+04\n","  3.59040483e+04  3.49052301e+04  3.29075935e+04  3.39064118e+04\n","  3.19087753e+04  2.94117296e+04  2.74140931e+04  2.49170474e+04\n","  2.29194109e+04  1.99231747e+04  1.79254459e+04  1.49288648e+04\n","  1.29312282e+04  9.93477344e+03  7.93713691e+03  4.94068212e+03\n","  2.94304559e+03  9.45409060e+02 -5.34092047e+01 -1.05222747e+03\n"," -2.05104573e+03 -4.04868226e+03 -5.04750053e+03 -6.04631879e+03\n"," -8.04395532e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.03470573e+03 -8.02929746e+03\n"," -6.04631879e+03 -4.03360820e+03 -5.47985455e+02  1.29512820e+03\n","  2.61020069e+03  4.94068212e+03  5.93950038e+03  6.93823954e+03\n","  7.93705481e+03  9.93462761e+03  1.09335316e+04  1.19324100e+04\n","  1.39300465e+04  1.49288648e+04  1.59276830e+04  1.69265013e+04\n","  1.79253196e+04  1.79253196e+04  1.89241378e+04  1.99229561e+04\n","  2.09217744e+04  2.19205926e+04  2.19205926e+04  2.29194109e+04\n","  2.39182291e+04  2.49170474e+04  2.49170474e+04  2.59158657e+04\n","  2.69146839e+04  2.79135022e+04  2.89123205e+04  2.89123205e+04\n","  2.99111387e+04  2.99111387e+04  2.99111387e+04  2.99111387e+04\n","  3.05770176e+04  3.09099570e+04  3.09099570e+04  3.09099570e+04\n","  3.19086943e+04  3.19087753e+04  3.19087753e+04  3.29075935e+04\n","  3.29075935e+04  3.29075935e+04  3.29075935e+04  3.39064118e+04\n","  3.49052301e+04  3.49052301e+04  3.59040483e+04  3.59113134e+04\n","  3.69028666e+04  3.69028666e+04  3.69028666e+04  3.69028666e+04\n","  3.75687455e+04  3.79016848e+04  3.79016848e+04  3.79016848e+04\n","  3.85605064e+04  3.89005031e+04  3.89005031e+04  3.89005031e+04\n","  3.79016848e+04  3.79016848e+04  3.79016848e+04  3.79016848e+04\n","  3.79016848e+04  3.79016848e+04  3.69028666e+04  3.69028666e+04\n","  3.59040483e+04  3.49052301e+04  3.49052301e+04  3.38991120e+04\n","  3.29075935e+04  3.28999118e+04  3.19087753e+04  3.12371356e+04\n","  3.02439142e+04  3.06110256e+04  3.01699797e+04  2.99111387e+04\n","  2.99111387e+04  2.99111387e+04  2.91688323e+04  2.89123205e+04\n","  2.89123205e+04  2.89123205e+04  2.89123205e+04  2.89123205e+04\n","  2.89123205e+04  2.89123205e+04  2.89123205e+04  2.89123205e+04\n","  2.95711350e+04  2.99111387e+04  2.91714337e+04  2.89123205e+04\n","  2.82463471e+04  2.69147562e+04  2.59159240e+04  2.39182291e+04\n","  2.19419927e+04  1.87992855e+04  1.56985931e+04  1.15709522e+04\n","  7.27088018e+03  2.43990178e+03 -3.04962139e+03 -6.03676889e+03\n"," -8.04395532e+03 -8.74384596e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -7.04513706e+03 -4.04868226e+03\n"," -1.05222747e+03  9.45409060e+02  2.94304559e+03  4.94068212e+03\n","  5.93950038e+03  6.93831865e+03  7.93713691e+03  8.93595518e+03\n","  1.15994706e+04  1.19400589e+04  1.29312282e+04  1.36142470e+04\n","  1.39300465e+04  1.39300465e+04  1.39300465e+04  1.46078939e+04\n","  1.55948390e+04  1.66276393e+04  1.89240127e+04  1.99229561e+04\n","  2.19204267e+04  2.19205926e+04  2.19205926e+04  2.19205926e+04\n","  2.19205926e+04  2.09217744e+04  1.99229561e+04  1.89241378e+04\n","  1.79253196e+04  1.69189965e+04  1.59195920e+04  1.49288648e+04\n","  1.65864986e+04  1.69265013e+04  1.76756751e+04  1.85970174e+04\n","  1.95830255e+04  2.09217014e+04  2.19205320e+04  2.29193344e+04\n","  2.39181473e+04  2.49170474e+04  2.59158657e+04  2.69146839e+04\n","  2.69146839e+04  2.69146839e+04  2.69146839e+04  2.69146839e+04\n","  2.59158657e+04  2.59158657e+04  2.49170474e+04  2.39182291e+04\n","  2.39182291e+04  2.29194109e+04  2.29194109e+04  2.29194109e+04\n","  2.19205926e+04  2.19129843e+04  2.16614794e+04  2.19205926e+04\n","  2.19205926e+04  2.19205926e+04  2.19205926e+04  2.19205926e+04\n","  2.09218438e+04  1.99258878e+04  1.99229561e+04  1.89241378e+04\n","  1.79253196e+04  1.79253196e+04  1.69265013e+04  1.69265013e+04\n","  1.59276830e+04  1.59276830e+04  1.39300465e+04  1.12521472e+04\n","  9.60164687e+03  7.52082097e+03  3.94205343e+03  9.45409060e+02\n"," -2.05104573e+03 -5.04750053e+03 -7.04513706e+03 -8.04395532e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -9.04277359e+03 -9.04277359e+03 -9.04277359e+03 -9.04277359e+03\n"," -8.04395532e+03 -8.04395532e+03 -8.04395532e+03 -7.04513706e+03\n"," -7.04513706e+03 -6.04631879e+03 -5.04991697e+03 -4.04868226e+03\n"," -2.05104573e+03 -1.05222747e+03  9.45409060e+02  2.94304559e+03\n","  2.94304559e+03  3.94186385e+03  4.94068212e+03  4.94068212e+03\n","  4.94068212e+03  4.94068212e+03  4.94068212e+03  4.94068212e+03\n","  4.94068212e+03  4.94068212e+03  4.94877315e+03  5.93950038e+03\n","  6.93831865e+03  7.93713691e+03  8.93595518e+03  8.94325564e+03\n","  9.94193447e+03  1.09412425e+04  1.19324100e+04  1.19397453e+04\n","  1.19324100e+04  1.39300465e+04  1.39462840e+04  1.59276830e+04\n","  1.79253196e+04  1.89317875e+04  1.99391380e+04  2.09217744e+04\n","  2.29194109e+04  2.49170474e+04  2.59158657e+04  2.69146839e+04\n","  2.79135022e+04  2.89123205e+04  2.89123205e+04  2.99111387e+04\n","  2.95782949e+04  2.94949644e+04  3.09051241e+04  3.09099570e+04\n","  3.19086943e+04  3.19087753e+04  3.29075935e+04  3.29075935e+04\n","  3.49052301e+04  3.59040483e+04  3.79016848e+04  3.89005031e+04\n","  3.98993214e+04  4.08981396e+04  4.08981396e+04  4.08981396e+04\n","  4.08981396e+04  4.08981396e+04  4.08981396e+04  4.08981396e+04\n","  3.98994024e+04  3.98993214e+04  3.98993214e+04  3.98993214e+04\n","  3.79018508e+04  3.89005031e+04  3.79016848e+04  3.89005031e+04\n","  3.89005031e+04  3.89005031e+04  3.98993214e+04  4.08981396e+04\n","  4.19111444e+04  4.39022761e+04  4.48934127e+04  4.65700674e+04\n","  4.82229941e+04  4.95886055e+04  5.13858468e+04  5.28838798e+04\n","  5.42157165e+04  5.58804136e+04  5.78779288e+04  5.98756867e+04\n","  5.98756867e+04  6.38595670e+04  6.58684699e+04  6.78662328e+04\n","  6.88650511e+04  6.88650511e+04  6.88650511e+04  6.78662328e+04\n","  6.78662328e+04  6.68674145e+04  6.61276051e+04  6.58685963e+04\n","  6.52098035e+04  6.48697780e+04  6.38732315e+04  6.38709597e+04\n","  6.38709597e+04  6.38709597e+04  6.38709597e+04  6.38709597e+04\n","  6.48697780e+04  6.58685963e+04  6.58685963e+04  6.68674145e+04\n","  6.78662328e+04  6.88650511e+04  6.98638693e+04  7.08626876e+04\n","  7.08626876e+04  7.08626876e+04  6.98638693e+04  7.08626876e+04\n","  7.08626876e+04  7.08626876e+04  7.01230134e+04  6.98638693e+04\n","  6.88682717e+04  6.88650511e+04  6.88650511e+04  6.88650511e+04\n","  6.88650511e+04  6.98638693e+04  6.98638693e+04  7.08626876e+04\n","  7.18615058e+04  7.38591424e+04  7.48579606e+04  7.38591424e+04\n","  7.68555972e+04  7.68555972e+04  7.68555972e+04  7.68555972e+04\n","  7.75214760e+04  7.88532337e+04  8.08507536e+04  8.18496885e+04\n","  8.38473250e+04  8.58449615e+04  8.68437215e+04  8.78425981e+04\n","  8.78425981e+04  8.68437798e+04  8.68437798e+04  8.68437798e+04\n","  8.58449615e+04  8.51373945e+04  8.48461433e+04  8.41683738e+04\n","  8.38473250e+04  8.38473250e+04  8.48461433e+04  8.58448827e+04\n","  8.58449615e+04  8.68437798e+04  8.78425981e+04  8.88414163e+04\n","  8.98402346e+04  9.08390529e+04  9.08390529e+04  9.08390529e+04\n","  9.08390529e+04  8.68437798e+04  8.98321436e+04  8.58668590e+04\n","  8.88414163e+04  8.88414163e+04  8.88414163e+04  8.88414163e+04\n","  8.95073897e+04  8.58449615e+04  9.05893483e+04  9.08390529e+04\n","  9.08390529e+04  9.08390529e+04  9.08390529e+04  9.08390529e+04\n","  9.01731740e+04  8.98402346e+04  8.98402346e+04  8.91686536e+04\n","  8.88414163e+04  8.81414555e+04  8.78425981e+04  8.78425981e+04\n","  8.78425981e+04  8.78425981e+04  8.85917724e+04  8.95192528e+04\n","  9.04990482e+04  9.18378003e+04  9.25870455e+04  9.28366894e+04\n","  9.28366894e+04  9.28366894e+04  9.28366894e+04  9.28366894e+04\n","  9.28366894e+04  9.28366894e+04  9.28366894e+04  9.38354336e+04\n","  9.38355077e+04  9.38355077e+04  9.38355077e+04  9.38355077e+04\n","  9.38355077e+04  9.38355077e+04  9.38355077e+04  9.38355077e+04\n","  9.38355077e+04  9.38355077e+04  9.38355077e+04  9.38355077e+04\n","  9.28366894e+04  9.28366894e+04  9.28366894e+04  9.28366894e+04\n","  9.28366894e+04  9.28366894e+04  9.28366894e+04  9.28366894e+04\n","  9.28366894e+04  9.28366894e+04  9.28366894e+04  9.18378711e+04\n","  8.88414163e+04  9.18378711e+04  9.18378711e+04  9.08390529e+04\n","  9.08390529e+04  8.98402346e+04  8.98402346e+04  8.88414163e+04\n","  8.88414163e+04  8.78425981e+04  8.70934238e+04  8.68437798e+04\n","  8.58450418e+04  8.58449615e+04  8.48462016e+04  8.48461433e+04\n","  8.38473250e+04  8.38473250e+04  7.98522340e+04  8.28485068e+04\n","  8.18496885e+04  8.18496885e+04  8.18496885e+04  8.08508702e+04\n","  8.08508702e+04  7.98520520e+04  7.83539938e+04  7.88532337e+04\n","  7.88532337e+04  7.88532337e+04  7.78544154e+04  7.78544154e+04\n","  7.78544154e+04  7.78544154e+04  7.78544154e+04  7.78544154e+04\n","  7.78544154e+04  7.78544154e+04  7.78544154e+04  7.78544154e+04\n","  7.78544154e+04  7.78544154e+04  7.68555972e+04  7.68555972e+04\n","  7.68555972e+04  7.68555972e+04  7.53760686e+04  7.78541789e+04\n","  7.78544154e+04  7.88532337e+04  7.88532337e+04  7.98520520e+04\n","  7.98520520e+04  7.88532337e+04  7.88532337e+04  7.78544154e+04\n","  7.78544154e+04  7.68555972e+04]\n","[1672.6741762088025]\n","==================================================================\n","/content/drive/MyDrive/AVL-RDE/22_Highway_DGPS_dyn_22082017_good_.csv\n","['d', 'spd_lim', 'tfc_flw', 'traf_lig', 'tfc_sgn', 'toll_booth', 'curvature', 'slope', 'velocity_kmh_raw']\n","['d', 'spd_lim', 'tfc_flw', 'traf_lig', 'tfc_sgn', 'toll_booth', 'curvature', 'slope', 'velocity_kmh_raw']\n","<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 468157 entries, 0 to 62153\n","Data columns (total 9 columns):\n"," #   Column            Non-Null Count   Dtype  \n","---  ------            --------------   -----  \n"," 0   d                 468157 non-null  float64\n"," 1   spd_lim           468157 non-null  float64\n"," 2   tfc_flw           468157 non-null  float64\n"," 3   traf_lig          468157 non-null  float64\n"," 4   tfc_sgn           468157 non-null  float64\n"," 5   toll_booth        468157 non-null  float64\n"," 6   curvature         468157 non-null  float64\n"," 7   slope             468157 non-null  float64\n"," 8   velocity_kmh_raw  468157 non-null  float64\n","dtypes: float64(9)\n","memory usage: 35.7 MB\n","None\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 672 entries, 0 to 671\n","Data columns (total 9 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   d                 672 non-null    float64\n"," 1   spd_lim           672 non-null    float64\n"," 2   tfc_flw           672 non-null    float64\n"," 3   traf_lig          672 non-null    float64\n"," 4   tfc_sgn           672 non-null    float64\n"," 5   toll_booth        672 non-null    float64\n"," 6   curvature         672 non-null    float64\n"," 7   slope             672 non-null    float64\n"," 8   velocity_kmh_raw  672 non-null    float64\n","dtypes: float64(9)\n","memory usage: 47.4 KB\n","None\n","           d  spd_lim  tfc_flw  traf_lig  tfc_sgn  toll_booth  curvature  \\\n","0   0.000000    130.0    115.0       0.0      0.0         0.0   0.000000   \n","1  15.555556    130.0    115.0       0.0      0.0         0.0   0.000943   \n","2  31.041667    130.0    115.0       0.0      0.0         0.0   0.000881   \n","3  46.458333    130.0    115.0       0.0      0.0         0.0   0.000448   \n","4  61.875000    130.0    115.0       0.0      0.0         0.0   0.000264   \n","\n","      slope  velocity_kmh_raw  \n","0  2.235268             112.0  \n","1  2.270774             112.0  \n","2  2.315803             111.0  \n","3  2.365939             111.0  \n","4  2.417110             111.0  \n","df_for_training_scaled.shape (468157, 9)\n","df_for_testing_scaled.shape (672, 9)\n","trainX shape == (468137, 20, 9).\n","trainY shape == (468137, 1).\n","testX shape == (652, 20, 9).\n","testY shape == (652, 1).\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_2 (LSTM)               (None, 20, 64)            18944     \n","                                                                 \n"," lstm_3 (LSTM)               (None, 32)                12416     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 31,393\n","Trainable params: 31,393\n","Non-trainable params: 0\n","_________________________________________________________________\n","26333/26333 [==============================] - 551s 21ms/step - loss: 9.9034 - accuracy: 0.0000e+00 - val_loss: 0.0627 - val_accuracy: 0.0000e+00\n","[[ 1.7620041   1.7620041   1.7620041  ...  1.7620041   1.7620041\n","   1.7620041 ]\n"," [ 1.7799518   1.7799518   1.7799518  ...  1.7799518   1.7799518\n","   1.7799518 ]\n"," [ 1.801091    1.801091    1.801091   ...  1.801091    1.801091\n","   1.801091  ]\n"," ...\n"," [ 0.02883642  0.02883642  0.02883642 ...  0.02883642  0.02883642\n","   0.02883642]\n"," [-0.00200594 -0.00200594 -0.00200594 ... -0.00200594 -0.00200594\n","  -0.00200594]\n"," [-0.04463493 -0.04463493 -0.04463493 ... -0.04463493 -0.04463493\n","  -0.04463493]]\n","(652,)\n","[ 88835.25   89383.51   90029.26   90732.92   89760.56   92717.17\n","  94246.945  95041.38   95848.78   97146.53   98087.54   98882.58\n","  99926.305 100721.09  101715.47  101849.1   102046.32  102033.414\n","  99217.08   98329.414 101484.74  101878.14  101731.57  101760.77\n"," 101882.74  101981.87  102079.195 102195.055 101726.83  101742.95\n"," 101717.17  102560.64  102743.375 102874.24  102967.85  103041.87\n"," 103202.875 102634.375 102861.49  103563.25  103653.85  103849.88\n"," 103898.48  103275.06  104917.195 106275.805 107006.234 108001.71\n"," 108718.02  109539.1   110836.18  111740.99  112334.08  113051.84\n"," 111518.914 111287.35  112411.28  112715.98  112820.49  112821.555\n"," 112331.68  110633.83  111745.24  112216.42  112361.62  112392.96\n"," 112476.34  112557.1   112623.62  112678.45  112747.38  112816.82\n"," 112857.85  112341.32  112211.24  111676.2   111520.73  110977.46\n"," 110806.39  110802.805 111196.31  111575.22  111715.164 111779.26\n"," 111840.62  111343.45  111196.21  110666.62  110497.26  110500.52\n"," 110516.12  107804.4   109476.65  110369.734 109958.87  110354.484\n"," 110025.62  109874.16  109883.2   109908.39  109595.414 109285.76\n"," 109489.664 109832.555 109945.484 110505.836 110733.67  111332.44\n"," 111567.48  111601.1   111653.68  112226.22  112446.58  112494.02\n"," 112507.37  111963.98  111757.5   111722.414 111704.78  111152.58\n"," 110941.234 110356.164 110126.625 110078.77  109520.695 109296.36\n"," 109243.63  109218.24  109209.77  108666.68  108442.39  108391.625\n"," 108360.4   108341.63  108330.58  108317.53  108297.92  108280.12\n"," 107935.97  107578.53  107985.88  108153.45  108699.72  109446.43\n"," 109687.734 110267.85  110477.28  111048.47  111258.73  111832.63\n"," 112035.34  112046.516 111506.19  111249.75  111156.19  110628.805\n"," 109806.42  109538.33  108936.98  108610.22  108019.734 107717.92\n"," 107137.05  106834.53  106788.96  106700.21  106674.83  107215.7\n"," 107898.11  108617.82  110331.766 111397.195 112286.27  111424.2\n"," 112883.055 113530.28  112989.945 112738.43  112734.8   112668.555\n"," 112025.98  111761.95  111754.43  111648.234 111630.42  111542.664\n"," 112090.914 112848.484 111923.25  112628.22  112984.93  113026.836\n"," 112980.97  112912.76  112950.19  112909.32  112828.64  112823.22\n"," 112791.36  112732.29  112677.89  112633.58  112605.17  112576.1\n"," 112557.586 112535.734 111917.55  112307.46  112454.07  111861.8\n"," 111663.81  111631.875 111611.4   111009.664 110813.97  110784.95\n"," 110763.44  110743.234 110725.71  110711.64  110701.234 110692.69\n"," 110686.98  111261.086 111429.89  112028.24  112205.08  112214.12\n"," 112218.984 112227.47  112240.305 112260.83  112287.414 112311.836\n"," 112332.82  112384.74  112373.04  112365.25  112456.06  112505.42\n"," 112509.35  112522.93  112552.07  112593.69  112626.31  112652.09\n"," 112676.14  112701.32  112728.97  112757.56  112786.51  112848.54\n"," 112845.984 112845.055 112936.82  112988.43  112994.625 113001.24\n"," 113028.375 114233.24  114582.19  114604.3   114613.09  114626.18\n"," 114641.59  114657.12  111781.79  113833.99  114632.23  114658.91\n"," 114645.72  114644.78  114652.63  114662.46  114681.83  114118.3\n"," 114006.92  113962.14  114028.695 113989.445 114042.26  113984.21\n"," 114034.766 113984.83  114018.96  114016.86  111251.555 113197.18\n"," 113517.484 111117.52  112663.83  113233.97  113317.914 113271.56\n"," 112772.12  112556.914 112612.12  112579.58  112645.29  112606.98\n"," 112664.375 112610.234 113242.2   113953.76  114703.46  115478.23\n"," 116327.72  117074.625 117342.375 117391.5   117421.055 117401.875\n"," 116715.42  113885.164 115841.93  116031.58  115898.19  115876.42\n"," 115279.93  115104.69  115113.61  115138.79  114592.336 114449.13\n"," 114464.59  111584.36  112986.5   113634.79  113671.695 113100.02\n"," 112333.94  112114.72  112128.06  111563.88  110819.67  107805.98\n"," 109053.99  109126.85  108416.15  108198.89  107596.05  105181.23\n"," 106535.58  107185.125 107291.91  107334.14  107908.125 108669.664\n"," 108901.695 108959.414 108992.89  109017.805 109584.19  110325.04\n"," 111696.43  112683.03  114066.62  115059.44  115877.26  116677.32\n"," 117516.125 117747.92  118380.31  119168.16  119963.07  120151.984\n"," 119562.03  118797.26  117437.74  116502.78  116316.27  115720.16\n"," 115540.18  115513.5   115500.84  115491.94  115494.13  115510.44\n"," 115537.08  114982.54  114832.875 114842.75  114855.81  114855.86\n"," 114842.195 114823.96  114800.56  114786.45  114784.2   114780.42\n"," 114783.28  114786.98  114733.76  114195.87  111758.984 113258.82\n"," 113909.055 113950.59  113956.78  113952.36  113947.055 113946.6\n"," 113954.4   113460.92  113268.07  113042.336 113038.06  112606.66\n"," 112452.664 112397.24  112381.61  112274.23  111749.86  111532.02\n"," 110988.91  108009.98  109772.76  110028.29  109902.85  109328.62\n"," 106904.33  108273.086 108929.5   108463.86  108239.74  108273.695\n"," 108239.8   108283.3   108237.52  108279.016 107676.28  107490.75\n"," 107458.38  107954.26  108151.03  108716.59  109469.97  108143.17\n"," 110279.67  111735.484 112616.945 113437.28  114235.99  114476.96\n"," 114524.45  114547.195 114560.62  114564.555 114550.63  114536.49\n"," 114516.266 114477.555 113742.88  113483.79  113634.27  113671.39\n"," 113702.1   113172.91  112972.695 112947.99  112944.63  112396.37\n"," 112189.92  112158.02  112115.2   111558.1   111373.44  111345.83\n"," 110765.78  110566.25  110528.266 110514.21  110508.414 110502.21\n"," 110496.836 110488.484 109923.48  109732.87  109707.64  109692.164\n"," 109125.29  108925.23  108889.2   108865.01  108850.88  108285.33\n"," 108079.25  108046.33  108034.38  108028.02  108025.195 108023.11\n"," 105816.6   107768.19  108632.65  108739.305 106011.71  107792.54\n"," 108635.38  108735.06  108768.266 108230.91  108044.79  107458.14\n"," 107249.09  107212.32  107197.4   107179.66  107164.59  107697.48\n"," 107871.92  107923.01  108500.21  109260.125 110034.664 108067.89\n"," 110147.5   111593.    111886.18  112507.88  112713.555 112741.67\n"," 112184.01  112010.69  109931.516 111176.04  112412.734 112693.445\n"," 113234.22  113459.29  113497.414 114028.12  114280.26  114329.98\n"," 114391.12  114423.    114429.77  114431.516 114425.63  113900.08\n"," 113657.77  113608.48  113578.984 113019.19  112715.97  112082.234\n"," 112018.73  112035.09  111505.4   111292.25  111256.53  111245.984\n"," 111242.68  110711.04  110504.74  110475.016 109948.7   109723.75\n"," 109656.56  108546.484 107651.47  107353.34  106592.86  105717.55\n"," 105620.516 104599.45  103599.69  102746.445 101498.414 100440.72\n","  99025.42   98012.234  96670.766  95088.914  93919.805  92969.04\n","  92128.45   91715.28   91075.164  90330.64   89952.586  89326.6\n","  88959.52   88145.75   87213.8    86916.21   86209.97   85765.414\n","  85608.86   85044.25   84275.13   83286.01   82950.79   82259.52\n","  80562.83   81132.27   81172.484  80465.984  80192.44   79578.984\n","  77333.96   77163.25   76244.83   75216.15   71776.64   70928.99\n","  69481.195  68916.66   67795.445  66582.76   64873.547  64549.29\n","  63664.81   62232.633  60558.63   58795.51   57406.32   55914.7\n","  54673.664  53617.75   52671.94   51766.16   51189.883  50520.145\n","  49726.848  49193.184  48556.047  47804.51   46979.523  46127.45\n","  45237.594  44288.184  43251.777  42235.08   41194.83   40493.348\n","  39736.582  38805.88   38107.902  37625.703  36930.465  36034.65\n","  35369.094  34865.926  34866.04   35296.375  35347.836  35717.83\n","  35884.1    35891.23   34949.07   33646.86 ]\n","y_testing_copies:  [[ 2.06818452  2.06818452  2.06818452 ...  2.06818452  2.06818452\n","   2.06818452]\n"," [ 2.10101971  2.10101971  2.10101971 ...  2.10101971  2.10101971\n","   2.10101971]\n"," [ 2.13423352  2.13423352  2.13423352 ...  2.13423352  2.13423352\n","   2.13423352]\n"," ...\n"," [-0.06610332 -0.06610332 -0.06610332 ... -0.06610332 -0.06610332\n","  -0.06610332]\n"," [-0.06610332 -0.06610332 -0.06610332 ... -0.06610332 -0.06610332\n","  -0.06610332]\n"," [-0.13174658 -0.13174658 -0.13174658 ... -0.13174658 -0.13174658\n","  -0.13174658]]\n","(652,)\n","[ 98188.30975379  99191.34445998 100205.94475815  98219.0200686\n"," 103868.13660974 104745.15485001 105789.62231203 106839.93495879\n"," 108214.02610538 109217.43313805 110224.72622809 111227.76093428\n"," 112230.79564047 113233.83034666 113233.83034666 113233.83034666\n"," 113233.83034666 108218.65681571 108218.65681571 113233.83034666\n"," 112230.79564047 112230.79564047 112230.79564047 112230.79564047\n"," 112230.79564047 112230.79564047 112225.05296587 111227.76093428\n"," 111227.76093428 111227.89343517 112230.79564047 112230.79564047\n"," 112230.79564047 112230.79564047 112230.79564047 112230.79564047\n"," 111227.76093428 111771.59722436 112230.79564047 112230.79564047\n"," 112230.79564047 112230.21157336 111146.68593989 113860.72703803\n"," 114908.9588893  115783.73093365 116828.62388299 117245.96917143\n"," 118390.51081033 119861.02398413 120834.95022194 121258.1079962\n"," 122260.73526969 119085.72239008 119588.2114832  121258.1079962\n"," 121258.1079962  121258.1079962  121258.1079962  120255.07329001\n"," 117610.69174857 120255.07329001 120255.07329001 120255.07329001\n"," 120255.07329001 120255.07329001 120255.07329001 120255.07329001\n"," 120255.07329001 120255.07329001 120255.07329001 120255.07329001\n"," 119252.03858382 119246.02177983 118249.00387762 118248.85091483\n"," 117245.96917143 117245.96917143 117245.96917143 117866.81776413\n"," 118249.00387762 118249.00387762 118249.00387762 118249.00387762\n"," 117249.53225162 117245.96917143 116243.43869079 116242.93446524\n"," 116242.93446524 116242.93446524 111227.76093428 116242.93446524\n"," 116242.93446524 115240.03366418 116242.93446524 115239.89975905\n"," 115239.89975905 115239.89975905 115239.89975905 114609.13616828\n"," 114236.86505286 114780.61478104 115239.89975905 115239.89975905\n"," 116242.40997839 116242.93446524 117245.96917143 117245.96917143\n"," 117245.96917143 117245.96917143 118249.00387762 118249.00387762\n"," 118249.00387762 118248.85522788 117245.96917143 117245.96917143\n"," 117245.96917143 117245.96917143 116242.93446524 116242.78551459\n"," 115239.89975905 115239.89975905 115239.89975905 114236.86505286\n"," 114236.86505286 114236.86505286 114236.86505286 114236.86505286\n"," 113233.83034666 113233.83034666 113233.83034666 113233.83034666\n"," 113233.83034666 113233.83034666 113233.83034666 113233.83034666\n"," 113233.83034666 112624.55797812 112230.79564047 113233.83034666\n"," 113233.83034666 114236.86505286 115239.89975905 115239.89975905\n"," 116242.93446524 116242.93446524 117245.96917143 117245.96917143\n"," 118249.00387762 118249.00387762 118243.36622075 117245.96917143\n"," 117245.96917143 117240.03240961 116242.93446524 115240.35373256\n"," 115239.89975905 114241.75424523 114236.86505286 113234.28421987\n"," 113233.83034666 112230.79564047 112230.79564047 112230.79564047\n"," 112230.79564047 112230.79564047 113233.83034666 114237.01801565\n"," 115240.18121059 117850.24191349 118828.82534174 119872.2364076\n"," 117948.94373829 121255.27632892 121258.1079962  120259.18492988\n"," 120255.07329001 120255.07329001 120255.07329001 119252.03858382\n"," 119252.03858382 119252.03858382 119252.03858382 119252.03858382\n"," 119257.76089681 120255.22214036 121229.65009612 119343.57854021\n"," 121258.1079962  121258.1079962  121258.1079962  121258.1079962\n"," 121258.1079962  121258.1079962  121258.1079962  121258.1079962\n"," 121258.1079962  121258.1079962  121258.1079962  121258.1079962\n"," 121258.1079962  121258.1079962  121258.1079962  121258.1079962\n"," 121258.1079962  120255.07329001 121258.1079962  121258.1079962\n"," 120255.07329001 120255.07329001 120255.07329001 120255.07329001\n"," 119252.03858382 119252.03858382 119252.03858382 119252.03858382\n"," 119252.03858382 119252.03858382 119252.03858382 119252.03858382\n"," 119252.03858382 119252.03858382 120255.07329001 120255.07329001\n"," 121258.1079962  121258.1079962  121258.1079962  121258.1079962\n"," 121258.1079962  121269.49354345 121304.20536492 121338.9172867\n"," 121373.62920847 121408.34102994 121443.05295171 121477.76477318\n"," 121512.47669496 121547.18861673 121581.9004382  121616.61235998\n"," 121651.32428175 121686.03610322 121720.74802499 121755.45994677\n"," 121790.17176824 121824.88369001 121859.59561179 121894.30743326\n"," 121929.01935503 121963.7312768  121998.44309827 122033.15502005\n"," 122067.86694182 122102.57876329 122137.29068506 122172.00260684\n"," 122206.71442831 122241.42635008 124267.21211478 124267.21211478\n"," 124267.21211478 124267.21211478 124267.21211478 124267.21211478\n"," 124267.21211478 119334.61140993 124267.21211478 124267.21211478\n"," 124267.21211478 124267.21211478 124267.21211478 124267.21211478\n"," 124267.21211478 124267.21211478 123264.17740858 123264.17740858\n"," 123264.17740858 123264.17740858 123264.17740858 123264.17740858\n"," 123264.17740858 123264.17740858 123264.17740858 123264.17740858\n"," 123264.17740858 118376.97997245 123264.17740858 122355.81814527\n"," 118474.41315895 122261.14270239 122261.14270239 122261.14270239\n"," 122261.14270239 121293.16054856 121258.1079962  121258.1079962\n"," 121258.1079962  121258.1079962  121258.1079962  121258.1079962\n"," 121258.1079962  122261.14270239 123264.17740858 124172.00095106\n"," 125206.02351176 126255.53984928 127172.93595377 127276.31623335\n"," 127276.31623335 127276.31623335 127205.3259505  126043.617172\n"," 121543.13766046 126214.43929855 125270.24682097 125270.24682097\n"," 125270.24682097 124267.21211478 124267.21211478 124267.21211478\n"," 124267.21211478 123264.17740858 123264.17740858 123264.17740858\n"," 118249.00387762 122261.14270239 122261.14270239 122261.14270239\n"," 121258.1079962  120255.07329001 120255.07329001 120255.07329001\n"," 119252.03858382 118249.00387762 113233.83034666 117245.96917143\n"," 116242.93446524 115239.89975905 115239.89975905 114236.86505286\n"," 110224.72622809 114236.86505286 114236.86505286 114236.86505286\n"," 114236.86505286 115239.89975905 116242.93446524 116242.93446524\n"," 116242.93446524 116242.93446524 116242.93446524 117245.96917143\n"," 118249.00387762 120255.07329001 121258.1079962  123264.17740858\n"," 124267.21211478 125270.24682097 126273.28152716 127276.31623335\n"," 127276.31623335 128279.35093954 129282.38564573 130285.42035193\n"," 130285.42035193 129282.38564573 128279.35093954 126273.28152716\n"," 125270.24682097 125270.24682097 124267.21211478 124267.21211478\n"," 124267.21211478 124267.21211478 124267.21211478 124267.21211478\n"," 124267.21211478 124267.21211478 123264.17740858 123264.17740858\n"," 123264.17740858 123264.17740858 123264.17740858 123264.17740858\n"," 123264.17740858 123264.17740858 123264.17740858 123264.17740858\n"," 123264.17740858 123264.17740858 123264.17740858 123167.90724082\n"," 122261.14270239 118284.98373557 122261.14270239 122261.14270239\n"," 122261.14270239 122261.14270239 122261.14270239 122261.14270239\n"," 122261.14270239 122261.14270239 121375.23356248 121258.1079962\n"," 120976.34641961 121127.24627083 120255.07329001 120255.07329001\n"," 120255.07329001 120255.07329001 120210.33663817 119252.03858382\n"," 119203.97486585 118249.00387762 113237.68601208 118249.00387762\n"," 117245.96917143 117245.96917143 116242.93446524 112230.79564047\n"," 116242.93446524 116242.93446524 115239.89975905 115239.89975905\n"," 115239.89975905 115239.89975905 115239.89975905 115239.89975905\n"," 115239.89975905 114236.86505286 114236.86505286 114236.86505286\n"," 115239.89975905 115239.89975905 116242.93446524 117245.96917143\n"," 114462.40593234 119252.03858382 120255.07329001 121258.1079962\n"," 122261.14270239 123238.74486179 123264.17740858 123264.17740858\n"," 123264.17740858 123264.17740858 123264.17740858 123264.17740858\n"," 123264.17740858 123264.17740858 123219.3903041  121990.02472829\n"," 121939.15522134 122261.14270239 122261.14270239 122261.14270239\n"," 121315.16702971 121258.1079962  121258.1079962  121258.1079962\n"," 120303.13269492 120255.07329001 120255.07329001 120201.27662688\n"," 119252.03858382 119252.03858382 119252.03858382 118249.00387762\n"," 118249.00387762 118249.00387762 118249.00387762 118249.00387762\n"," 118249.00387762 118249.00387762 118249.00387762 117245.96917143\n"," 117245.96917143 117245.96917143 117244.55047914 116242.93446524\n"," 116242.93446524 116242.93446524 116242.93446524 116242.93446524\n"," 115239.89975905 115239.89975905 115239.89975905 115239.89975905\n"," 115239.89975905 115239.89975905 115239.89975905 111227.76093428\n"," 116242.93446524 116242.93446524 116242.93446524 111227.76093428\n"," 116242.93446524 116242.93446524 116242.93446524 116242.93446524\n"," 115239.89975905 115239.89975905 114236.86505286 114236.86505286\n"," 114236.86505286 114236.86505286 114236.86505286 114236.86505286\n"," 115239.89975905 115239.89975905 115239.89975905 116242.93446524\n"," 117245.96917143 118249.00387762 114236.86505286 119252.03858382\n"," 120255.07329001 120255.07329001 121258.1079962  121258.1079962\n"," 121258.1079962  120255.07329001 120255.07329001 116598.55961789\n"," 120027.04959872 121232.51275717 121258.1079962  122158.35351116\n"," 122261.14270239 122261.14270239 123146.99206143 123264.17740858\n"," 123264.17740858 123264.17740858 123264.17740858 123264.17740858\n"," 123264.17740858 123264.17740858 122377.38880784 122261.14270239\n"," 122261.14270239 122261.14270239 121258.1079962  121028.42528551\n"," 120026.91489116 120255.07329001 120255.07329001 119328.25959235\n"," 119252.03858382 119252.03858382 119252.03858382 119252.03858382\n"," 118305.97614863 118249.00387762 118249.00387762 117321.6823435\n"," 117245.96917143 117196.64714643 115239.89975905 114324.54783928\n"," 114236.86505286 112988.23539309 111901.75712635 112230.79564047\n"," 110338.73807373 109237.95593026 108218.65681571 106403.87855942\n"," 105257.59274347 103219.35610836 102310.486501   100359.75621851\n","  98300.94864553  97210.83608314  96182.2403414   95276.92669268\n","  95179.20563521  94195.48566623  93281.1750971   93173.13622283\n","  92228.05385285  92170.10151663  90951.91847386  89968.59008963\n","  90164.03210425  89179.74672461  89160.99739806  89096.42974704\n","  88157.96269187  87192.43857489  86151.89327948  86151.89327948\n","  85032.88418994  82321.4154746   85087.39621742  84145.8238671\n","  83142.78916091  83142.78916091  82139.74191678  78127.61562995\n","  80133.68504233  78127.61562995  77124.58092376  76121.54621756\n","  71106.37268661  69186.6754955   71106.37268661  69295.74528885\n","  67964.20237298  65210.38011596  67094.23386184  65088.16444945\n","  63082.09503707  61076.02562469  59068.39187938  58066.92150611\n","  56060.85209373  55057.81738754  54054.78268134  53051.74797515\n","  52048.71326896  52048.71326896  51045.67856277  50042.64385658\n","  50042.64385658  49039.60915038  48036.57444419  47033.539738\n","  46030.50503181  45027.47032562  44024.43561942  43021.40091323\n","  42064.85877144  41035.19840867  41015.33150085  40086.70060522\n","  39068.2842615   39009.26208847  38938.83069656  37950.299471\n","  37003.19267608  36955.10448407  36000.15796989  36000.15796989\n","  35941.67563013  33994.08855751  34995.70697869  33994.08855751\n","  33935.53510259  32991.05385131  32991.05385131  30985.8131462 ]\n","[1672.6741762088025, 7129.2325771813885]\n","==================================================================\n","/content/drive/MyDrive/AVL-RDE/25_Highway_DGPS_dyn_22082017_ideal_part1.csv\n","['d', 'spd_lim', 'tfc_flw', 'traf_lig', 'tfc_sgn', 'toll_booth', 'curvature', 'slope', 'velocity_kmh_raw']\n","['d', 'spd_lim', 'tfc_flw', 'traf_lig', 'tfc_sgn', 'toll_booth', 'curvature', 'slope', 'velocity_kmh_raw']\n","<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 467922 entries, 0 to 62153\n","Data columns (total 9 columns):\n"," #   Column            Non-Null Count   Dtype  \n","---  ------            --------------   -----  \n"," 0   d                 467922 non-null  float64\n"," 1   spd_lim           467922 non-null  float64\n"," 2   tfc_flw           467922 non-null  float64\n"," 3   traf_lig          467922 non-null  float64\n"," 4   tfc_sgn           467922 non-null  float64\n"," 5   toll_booth        467922 non-null  float64\n"," 6   curvature         467922 non-null  float64\n"," 7   slope             467922 non-null  float64\n"," 8   velocity_kmh_raw  467922 non-null  float64\n","dtypes: float64(9)\n","memory usage: 35.7 MB\n","None\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 907 entries, 0 to 906\n","Data columns (total 9 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   d                 907 non-null    float64\n"," 1   spd_lim           907 non-null    float64\n"," 2   tfc_flw           907 non-null    float64\n"," 3   traf_lig          907 non-null    float64\n"," 4   tfc_sgn           907 non-null    float64\n"," 5   toll_booth        907 non-null    float64\n"," 6   curvature         907 non-null    float64\n"," 7   slope             907 non-null    float64\n"," 8   velocity_kmh_raw  907 non-null    float64\n","dtypes: float64(9)\n","memory usage: 63.9 KB\n","None\n","           d  spd_lim  tfc_flw  traf_lig  tfc_sgn  toll_booth  curvature  \\\n","0   0.000000    100.0    100.0       0.0      0.0         0.0   0.000000   \n","1  11.619905    100.0    100.0       0.0      0.0         0.0  -0.000102   \n","2  23.170365    100.0    100.0       0.0      0.0         0.0   0.000105   \n","3  34.698142    100.0    100.0       0.0      0.0         0.0   0.000178   \n","4  46.225920    100.0    100.0       0.0      0.0         0.0   0.000095   \n","\n","      slope  velocity_kmh_raw  \n","0  1.308312         84.000000  \n","1  1.301408         83.326624  \n","2  1.281046         83.000000  \n","3  1.256778         83.000000  \n","4  1.233012         83.000000  \n","df_for_training_scaled.shape (467922, 9)\n","df_for_testing_scaled.shape (907, 9)\n","trainX shape == (467902, 20, 9).\n","trainY shape == (467902, 1).\n","testX shape == (887, 20, 9).\n","testY shape == (887, 1).\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_4 (LSTM)               (None, 20, 64)            18944     \n","                                                                 \n"," lstm_5 (LSTM)               (None, 32)                12416     \n","                                                                 \n"," dropout_2 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 31,393\n","Trainable params: 31,393\n","Non-trainable params: 0\n","_________________________________________________________________\n","26320/26320 [==============================] - 579s 22ms/step - loss: 15.6939 - accuracy: 0.0000e+00 - val_loss: 0.7424 - val_accuracy: 0.0000e+00\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-e2433999b9c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m  \u001b[0;31m#history =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m  \u001b[0;31m#plt.plot(history.history['loss'], label='Training loss')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m  \u001b[0;31m#plt.plot(history.history['val_loss'], label='Validation loss')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["_training = data_train.copy()\n","testing  =  data_test.copy()\n","X= training.iloc[:,:-1].values\n","y= training.iloc[:,-1].values\n","print(y.shape)\n","y=y.reshape(-1,1)\n","print(y.shape)\n","x_te= testing.iloc[:,:-1].values\n","y_te= testing.iloc[:,-1].values\n","y_te=y_te.reshape(-1,1)\n","#print(type(x))\n","#print(type(y))\n","#y= dd['velocity_kmh_raw']\n","#print(type(y))\n","#print(y.shape)\n","#Splitting the data into training and testing\n","sc_x = StandardScaler()\n","sc_y = StandardScaler()\n","x_train_scaled = sc_x.fit_transform(X)\n","print(x_train_scaled.shape)\n","y_train_scaled = sc_y.fit_transform(y)\n","#sc_y= StandardScaler()\n","x_test_scaled = sc_x.transform(x_te)\n","y_test_scaled = sc_y.transform(y_te)\n","\n","pca_RDE = PCA(n_components=7,svd_solver='auto')\n","x_train_reduction = pca_RDE.fit_transform(x_train_scaled)\n","x_test_reduction = pca_RDE.transform(x_test_scaled)\n","\n","\n","RandomForestR = RandomForestRegressor()\n","#multi_model = LinearRegression()\n","RandomForestR.fit(x_train_reduction, y_train_scaled)\n","#multi_model.fit(x_train_reduction, y_train_scaled)\n","y_prediction = RandomForestR.predict(x_test_reduction)\n","#y_prediction = multi_model.predict(x_test_reduction)\n","\n","y_prediction =  y_prediction.reshape(-1,1)\n","#print(y_prediction[:5])\n","#print(y_test_scaled[:5])\n","print(np.min(y_test_scaled))\n","print(np.max(y_test_scaled))\n","\n","#print (y_prediction.shape)\n","#print(y_test.shape)\n","\n","MAE = mean_absolute_error(y_test_scaled,y_prediction, multioutput= 'uniform_average')\n","print('Mean Absolute Error Value is: ', MAE)\n","MSE = mean_squared_error(y_test_scaled,y_prediction, multioutput= 'uniform_average')\n","print('Mean Squared Error Value is: ', MSE)\n","print('Root Mean Squared Error Value is: ', math.sqrt(MSE))\n","#print(RandomForestR.feature_importances_)\n","y_prediction_unscaled = sc_y.inverse_transform(y_prediction)\n","Accumulated.append(mean_absolute_error(y_te, y_prediction_unscaled))\n","print(Accumulated)\n","print('==================================================================')\n","\n","#print(Accumulated)\n","print(np.mean(Accumulated))"],"metadata":{"id":"ajCefZCAbIY0"},"execution_count":null,"outputs":[]}]}